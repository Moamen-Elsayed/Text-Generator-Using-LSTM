{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text_Generator_Using_LSTM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMIOOj5JbObjtzD9TRspkK0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btbCGgs7P1KC","executionInfo":{"status":"ok","timestamp":1621409183765,"user_tz":420,"elapsed":791,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"03151fd9-bc8e-49e8-babc-85df6b5c0380"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":183,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMabGRSjQAga","executionInfo":{"status":"ok","timestamp":1621409184201,"user_tz":420,"elapsed":1215,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"2eed9b2b-643c-43e4-96fe-855a303c7a62"},"source":["with open('/content/gdrive/MyDrive/Copy of sponge_bob_transcript.txt', 'r') as f:\n","  text = f.read()\n","\n","print(text[:2000])"],"execution_count":184,"outputs":[{"output_type":"stream","text":["Mr Krabs: Where could they be? They should've been here hours ago! Arrgh! Not a customer in sight. If I don't make any money today, I surely break out in a rash!\n","Spongebob: Yippee! I'm rich! Look Patrick, eight gold dubloons!\n","Mr Krabs: Wait, I saw it first! hah! (Jumps onto table) Mine, mine! Huh?\n","Spongebob: Boy Mr Krabs, you sure are sweaty.\n","Mr Krabs: What's this? Where are the dubloons?\n","Spongebob: (laughs) There are no real dubloons, Mr Krabs! It's a game: 'The Flying Dutchman's Treasure Hunt'.\n","Patrick: Based on a real treasure map.\n","Spongebob: Take a break and play around with us.\n","Patrick: Yeah! C'mon sweaty.\n","Mr Krabs: Have you finished cleaning the tables?\n","Spongebob: I cleaned the tables Mr Krabs!\n","Mr Krabs: Ay, but did you scrape all the gum off the underside?\n","Spongebob: (chewing) I already took care of it.\n","Mr Krabs: Ha ha ha. All right, lads. Looks like you've shanghaeided me.\n","Patrick: My turn. (rolls dice) Five. (makes strawberry noise while moving piece) (reads card) One of your shipmates has been a bad pirate! Send him to the brig! Hmmm. (Spongebob turns eyes toward Mr Krabs) It's off to jail for you, Mr Krabs.\n","Mr Krabs: Patrick, you're fired!\n","Patrick: But I don't even work here!\n","Mr Krabs: Would you like a job, starting now? (puts hat on Patrick's head)\n","Patrick: Boy, would I?!\n","Mr Krabs: (takes hat off Patrick's head) You're fired!\n","Spongebob: My turn. (rolls dice) One, two, three, four. (picks up card and reads it) Look for the Deacon's Goose thru the fork in the old tree and head that way. Well, I see Mr Krabs zipper is undone.\n","Mr Krabs: Uhh! Shiver me timbers!\n","Spongebob: (laughs) Just kidding, Mr Krabs. I'm almost to the treasure. You're turn again Mr Krabs.\n","Mr Krabs: (rolls dice) Ooh, fish eyes. One, two.\n","Spongebob: (picks up card and reads it) You are a real pirate. Go straight to the \"X\" that marks the spot. You get to dig for treasure Mr Krabs!\n","Mr Krabs: Treasure. (digs and mini plastic treasure chest appears) There it is! It's the Flying Dutchman's Trea\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hI1azw0rQlea","executionInfo":{"status":"ok","timestamp":1621409184203,"user_tz":420,"elapsed":1208,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"5fb5f9d0-3b42-4649-fda5-042e1033b260"},"source":["import numpy as np\n","\n","num_lines = len(text.split('\\n'))\n","num_unique_words = np.unique(text.split()).shape[0]\n","\n","print('Number of lines = {}'.format(num_lines))\n","print('Number of unique words = {}'.format(num_unique_words))"],"execution_count":185,"outputs":[{"output_type":"stream","text":["Number of lines = 8819\n","Number of unique words = 17682\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"id":"ZGEbfip8SsIZ","executionInfo":{"status":"ok","timestamp":1621409184206,"user_tz":420,"elapsed":1201,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"42d5568c-c72b-4dc5-89f7-5ab96b4f4ebe"},"source":["dict_punctuation = {\n","        \".\":\"||Period||\",\n","        \",\":\"||Comma||\",\n","        \"\\\"\":\"||Quotation||\",\n","        \";\":\"||SemiColon||\",\n","        \":\":\"||Colon||\",\n","        \"!\":\"||Exclamation||\",\n","        \"?\":\"||QuestionMark||\",\n","        \")\":\"||LeftParentheses||\",\n","        \"(\":\"||RightParentheses||\",\n","        \"-\":\"||Dash||\",\n","        \"\\n\":\"||Return||\"\n","    }\n","\n","def encode_punctuation(text):\n","    '''\n","    Function to replace all punctuation by encoded words\n","\n","    Parameters\n","    ----------\n","    text: string\n","      string to encode punctuation for\n","\n","    Returns\n","    -------\n","    string\n","        The encoded string after punctutation was replaced with words \n","    '''\n","\n","    for key, token in dict_punctuation.items():\n","        text = text.replace(key, ' {} '.format(token))\n","    \n","    return text\n","\n","encode_punctuation(text[:500])"],"execution_count":186,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Mr Krabs ||Colon||  Where could they be ||QuestionMark||  They should've been here hours ago ||Exclamation||  Arrgh ||Exclamation||  Not a customer in sight ||Period||  If I don't make any money today ||Comma||  I surely break out in a rash ||Exclamation||  ||Return|| Spongebob ||Colon||  Yippee ||Exclamation||  I'm rich ||Exclamation||  Look Patrick ||Comma||  eight gold dubloons ||Exclamation||  ||Return|| Mr Krabs ||Colon||  Wait ||Comma||  I saw it first ||Exclamation||  hah ||Exclamation||   ||RightParentheses|| Jumps onto table ||LeftParentheses||  Mine ||Comma||  mine ||Exclamation||  Huh ||QuestionMark||  ||Return|| Spongebob ||Colon||  Boy Mr Krabs ||Comma||  you sure are sweaty ||Period||  ||Return|| Mr Krabs ||Colon||  What's this ||QuestionMark||  Where are the dubloons ||QuestionMark||  ||Return|| Spongebob ||Colon||   ||RightParentheses|| laughs ||LeftParentheses||  There are no real dubloons ||Comma||  Mr Krabs ||Exclamation||  It's a game ||Colon||  'The Flying Dutchman's Treasure Hunt'\""]},"metadata":{"tags":[]},"execution_count":186}]},{"cell_type":"code","metadata":{"id":"Zs9YQz4fTdrf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621409184208,"user_tz":420,"elapsed":1195,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"f239bb20-7b21-4bed-9990-175be3ca1ad5"},"source":["from collections import Counter\n","import pprint\n","\n","def create_encoding(text):\n","    \n","    word_counts = Counter(text)\n","    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n","    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n","    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n","\n","    return (vocab_to_int, int_to_vocab)\n","\n","create_encoding(encode_punctuation(text[:500]).split())"],"execution_count":187,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({\"'The\": 71,\n","  'Arrgh': 26,\n","  'Boy': 58,\n","  \"Dutchman's\": 73,\n","  'Flying': 72,\n","  'Huh': 57,\n","  \"Hunt'\": 75,\n","  'I': 8,\n","  \"I'm\": 41,\n","  'If': 30,\n","  \"It's\": 69,\n","  'Jumps': 52,\n","  'Krabs': 4,\n","  'Look': 43,\n","  'Mine': 55,\n","  'Mr': 3,\n","  'Not': 27,\n","  'Patrick': 44,\n","  'Spongebob': 9,\n","  'There': 66,\n","  'They': 20,\n","  'Treasure': 74,\n","  'Wait': 47,\n","  \"What's\": 62,\n","  'Where': 12,\n","  'Yippee': 40,\n","  'a': 7,\n","  'ago': 25,\n","  'any': 33,\n","  'are': 11,\n","  'be': 19,\n","  'been': 22,\n","  'break': 37,\n","  'could': 17,\n","  'customer': 28,\n","  \"don't\": 31,\n","  'dubloons': 10,\n","  'eight': 45,\n","  'first': 50,\n","  'game': 70,\n","  'gold': 46,\n","  'hah': 51,\n","  'here': 23,\n","  'hours': 24,\n","  'in': 13,\n","  'it': 49,\n","  'laughs': 65,\n","  'make': 32,\n","  'mine': 56,\n","  'money': 34,\n","  'no': 67,\n","  'onto': 53,\n","  'out': 38,\n","  'rash': 39,\n","  'real': 68,\n","  'rich': 42,\n","  'saw': 48,\n","  \"should've\": 21,\n","  'sight': 29,\n","  'sure': 60,\n","  'surely': 36,\n","  'sweaty': 61,\n","  'table': 54,\n","  'the': 64,\n","  'they': 18,\n","  'this': 63,\n","  'today': 35,\n","  'you': 59,\n","  '||Colon||': 1,\n","  '||Comma||': 2,\n","  '||Exclamation||': 0,\n","  '||LeftParentheses||': 16,\n","  '||Period||': 14,\n","  '||QuestionMark||': 6,\n","  '||Return||': 5,\n","  '||RightParentheses||': 15},\n"," {0: '||Exclamation||',\n","  1: '||Colon||',\n","  2: '||Comma||',\n","  3: 'Mr',\n","  4: 'Krabs',\n","  5: '||Return||',\n","  6: '||QuestionMark||',\n","  7: 'a',\n","  8: 'I',\n","  9: 'Spongebob',\n","  10: 'dubloons',\n","  11: 'are',\n","  12: 'Where',\n","  13: 'in',\n","  14: '||Period||',\n","  15: '||RightParentheses||',\n","  16: '||LeftParentheses||',\n","  17: 'could',\n","  18: 'they',\n","  19: 'be',\n","  20: 'They',\n","  21: \"should've\",\n","  22: 'been',\n","  23: 'here',\n","  24: 'hours',\n","  25: 'ago',\n","  26: 'Arrgh',\n","  27: 'Not',\n","  28: 'customer',\n","  29: 'sight',\n","  30: 'If',\n","  31: \"don't\",\n","  32: 'make',\n","  33: 'any',\n","  34: 'money',\n","  35: 'today',\n","  36: 'surely',\n","  37: 'break',\n","  38: 'out',\n","  39: 'rash',\n","  40: 'Yippee',\n","  41: \"I'm\",\n","  42: 'rich',\n","  43: 'Look',\n","  44: 'Patrick',\n","  45: 'eight',\n","  46: 'gold',\n","  47: 'Wait',\n","  48: 'saw',\n","  49: 'it',\n","  50: 'first',\n","  51: 'hah',\n","  52: 'Jumps',\n","  53: 'onto',\n","  54: 'table',\n","  55: 'Mine',\n","  56: 'mine',\n","  57: 'Huh',\n","  58: 'Boy',\n","  59: 'you',\n","  60: 'sure',\n","  61: 'sweaty',\n","  62: \"What's\",\n","  63: 'this',\n","  64: 'the',\n","  65: 'laughs',\n","  66: 'There',\n","  67: 'no',\n","  68: 'real',\n","  69: \"It's\",\n","  70: 'game',\n","  71: \"'The\",\n","  72: 'Flying',\n","  73: \"Dutchman's\",\n","  74: 'Treasure',\n","  75: \"Hunt'\"})"]},"metadata":{"tags":[]},"execution_count":187}]},{"cell_type":"code","metadata":{"id":"7wQatYd3qHTW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621409184505,"user_tz":420,"elapsed":1486,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"790c412e-55ad-4414-9600-556337b3cacb"},"source":["text = encode_punctuation(text)\n","\n","text = text.lower().split()\n","\n","vocab_to_int, int_to_vocab = create_encoding(text)\n","print(\"Number of unique words: {}\".format(len(vocab_to_int)))\n","\n","np.save(\"encodings.npy\",[vocab_to_int,int_to_vocab])\n","\n","text_encoded = [vocab_to_int[word] for word in text]"],"execution_count":188,"outputs":[{"output_type":"stream","text":["Number of unique words: 8028\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2pHXDB4wZoLl","executionInfo":{"status":"ok","timestamp":1621409184508,"user_tz":420,"elapsed":1482,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}}},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","def prepare_data(words, seq_len, batch_size):\n","  features, targets = [], []\n","  for i in range(0, len(words)-seq_len):\n","    features.append(words[i:i+seq_len])\n","    targets.append(words[i+seq_len])\n","\n","  features_tensor = torch.LongTensor(features)\n","  targets_tensor = torch.LongTensor(targets)\n","\n","  dataset = TensorDataset(features_tensor, targets_tensor)\n","  data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","  return data_loader"],"execution_count":189,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8jkn6qvZuxB","executionInfo":{"status":"ok","timestamp":1621409184510,"user_tz":420,"elapsed":1478,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"8b287f25-e93b-4c78-9383-67479d9fad12"},"source":["# test my dataloader\n","\n","test_text = np.arange(100)\n","temp_loader = prepare_data(test_text, seq_len=5, batch_size=10)\n","\n","data_iter = iter(temp_loader)\n","sample_x, sample_y = data_iter.next()\n","\n","print('Features shape: {}'.format(sample_x.shape))\n","print('Features')\n","print(sample_x)\n","\n","print('*'*20)\n","\n","print('Targets shape: {}'.format(sample_y.shape))\n","print('Targets')\n","print(sample_y)"],"execution_count":190,"outputs":[{"output_type":"stream","text":["Features shape: torch.Size([10, 5])\n","Features\n","tensor([[ 2,  3,  4,  5,  6],\n","        [62, 63, 64, 65, 66],\n","        [27, 28, 29, 30, 31],\n","        [32, 33, 34, 35, 36],\n","        [33, 34, 35, 36, 37],\n","        [67, 68, 69, 70, 71],\n","        [26, 27, 28, 29, 30],\n","        [42, 43, 44, 45, 46],\n","        [49, 50, 51, 52, 53],\n","        [50, 51, 52, 53, 54]])\n","********************\n","Targets shape: torch.Size([10])\n","Targets\n","tensor([ 7, 67, 32, 37, 38, 72, 31, 47, 54, 55])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aowTil8Ng6Yv","executionInfo":{"status":"ok","timestamp":1621409184511,"user_tz":420,"elapsed":1472,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"d7a0fe8e-5755-44fc-dc37-059666e5802b"},"source":["# Check GPU Avilability\n","\n","is_CUDA = torch.cuda.is_available()\n","if is_CUDA:\n","  print('Hello CUDA :)')\n","else:\n","  print('Hello CPU :(')"],"execution_count":191,"outputs":[{"output_type":"stream","text":["Hello CUDA :)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oMs8Ei-AjKY9","executionInfo":{"status":"ok","timestamp":1621409184513,"user_tz":420,"elapsed":1468,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}}},"source":["import torch.nn as nn\n","\n","class RNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers,dropout=0.5):\n","        '''\n","        Recurrent PyTorch model with an embedding layer\n","\n","        Parameters\n","        ----------\n","        vocab_size:\n","          The number of input dimensions of the neural network (number of words in the vocabulary)\n","        embedding_dim:\n","          The size of embeddings, should you choose to use them        \n","        hidden_dim:\n","          The size of the hidden layer outputs\n","        dropout:\n","          dropout to add in between LSTM/GRU layers\n","        '''\n","        super(RNN, self).__init__()\n","        \n","        self.vocab_size = vocab_size\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","\n","        self.embedd = nn.Embedding(vocab_size,embedding_dim)\n","        self.LSTM = nn.LSTM(embedding_dim,hidden_dim,n_layers,dropout=dropout,batch_first=True)\n","        self.fc = nn.Linear(hidden_dim,vocab_size)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","    \n","    \n","    def forward(self, nn_input, hidden):\n","        \"\"\"\n","        Forward propagation of the neural network\n","\n","        Parameters\n","        ----------\n","        nn_input:\n","          The input to the neural network\n","        hidden:\n","          The hidden state\n","\n","        Returns\n","        -------  \n","          Two Tensors, the output of the neural network and the latest hidden state\n","        \"\"\"\n","        batch_size = nn_input.shape[0]\n","        \n","        embedded_vector = self.embedd(nn_input)\n","        \n","        LSTM_output,hidden = self.LSTM(embedded_vector,hidden)\n","        \n","        LSTM_output = self.dropout(LSTM_output.reshape(-1,self.hidden_dim))\n","        \n","        output = self.fc(LSTM_output)\n","        \n","        output = output.reshape(batch_size, -1, self.vocab_size)\n","        \n","        # get last batch\n","        out = output[:, -1]\n","        \n","        # return one batch of output word scores and the hidden state\n","        return out,hidden\n","    \n","    \n","    def init_hidden(self, batch_size):\n","        '''\n","        Initialize the hidden state of an LSTM/GRU\n","        Parameters\n","        ----------\n","        batch_size: int\n","            batch_size to use to generate hidden layer\n","\n","        Returns\n","        -------\n","        tuple = (torch.FloatTensor,torch.FloatTensor), shape of each tensor = (self.n_layers,batch_size,self.hidden_dim)\n","            The initial hidden state containing all zeros, if using GPU, the tensors should be torch.cuda.FloatTensor (i.e. on the GPU)\n","        '''\n","        # Initialize hidden state with zero weights\n","        hidden = (torch.zeros(self.n_layers, batch_size, self.hidden_dim),\n","                  torch.zeros(self.n_layers, batch_size, self.hidden_dim))\n","        \n","        # If using GPU move hidden state to GPU\n","        if is_CUDA:\n","            hidden = hidden[0].cuda(),hidden[1].cuda()\n","        \n","        return hidden"],"execution_count":192,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4G6KJvjsKZS","executionInfo":{"status":"ok","timestamp":1621409184514,"user_tz":420,"elapsed":1465,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}}},"source":["def forward_back_prop(model, optimizer, criterion, inp, target, hidden):\n","\n","  if is_CUDA:\n","      inp, target = inp.cuda(), target.cuda()\n","    \n","  hidden = tuple([each.data for each in hidden])\n","\n","  optimizer.zero_grad()\n","    \n","  pred, hidden_state = model.forward(inp, hidden)\n","    \n","  loss = criterion(pred.squeeze(), target)\n","  loss.backward()\n","    \n","  nn.utils.clip_grad_norm_(model.parameters(), 5)\n","  optimizer.step()\n","\n","  return loss.item(), hidden_state"],"execution_count":193,"outputs":[]},{"cell_type":"code","metadata":{"id":"vtP1H_GjUs54","executionInfo":{"status":"ok","timestamp":1621409184515,"user_tz":420,"elapsed":1461,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","sns.set()\n","\n","def train_rnn(model, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n","    batch_losses = []\n","    training_losses = []\n","\n","    n_train_batches = len(train_loader.dataset)//batch_size\n","\n","    print(\"Training for %d epoch(s)...\" % n_epochs)\n","    for e in range(1, n_epochs + 1):\n","        \n","        hidden = model.init_hidden(batch_size) # Initialize hidden state\n","\n","        train_loss_epoch = []\n","        model.train()\n","        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n","            \n","            # make sure you iterate over completely full batches, only\n","            if(batch_i > n_train_batches):\n","                break\n","            \n","            # forward, back prop\n","            loss, hidden = forward_back_prop(model, optimizer, criterion, inputs, labels, hidden)\n","\n","            # record loss\n","            batch_losses.append(loss)\n","            train_loss_epoch.append(loss)\n","\n","            # printing loss stats\n","            if batch_i % show_every_n_batches == 0:\n","                print('Epoch: {}/{}  Training Loss: {}\\n'.format(e, n_epochs, np.average(batch_losses)))\n","                batch_losses = []\n","\n","        training_losses.append(np.average(train_loss_epoch))\n","\n","        # Save Model\n","        torch.save(model,'trained_LSTM.pt')\n","\n","    # Plot training and validation losses\n","    plt.plot(training_losses,label=\"Training Loss\")\n","    plt.ylabel(\"CrossEntropy Loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.title(\"Training losses\")\n","    plt.show()\n","\n","    return model"],"execution_count":194,"outputs":[]},{"cell_type":"code","metadata":{"id":"17YUynoCYxFA","executionInfo":{"status":"ok","timestamp":1621409184516,"user_tz":420,"elapsed":1458,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}}},"source":["##################### Hyperparameters #####################\n","\n","# Data parameters\n","sequence_length = 30  # number of words in a sequence\n","batch_size = 128  # number of sequences in a batch\n","train_ratio = 0.8\n","num_train_words = int(len(text_encoded)*0.8)\n","\n","# Training parameters\n","num_epochs = 50\n","lr = 8e-3\n","\n","# Model parameters\n","vocab_size = len(vocab_to_int)\n","embedding_dim = 200\n","hidden_dim = 256\n","n_layers = 2  # number of LSTM Layers\n","\n","# Logging parameters\n","show_every_n_batches = 500  # show stats for every n number of batches"],"execution_count":195,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUKbZt8dY89w","executionInfo":{"status":"ok","timestamp":1621409185277,"user_tz":420,"elapsed":2214,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"cc4d714a-1727-4133-b64d-3772106bcbb8"},"source":["# Create dataloader\n","train_loader = prepare_data(text_encoded[:num_train_words], sequence_length, batch_size)\n","\n","# Create model\n","model = RNN(vocab_size, embedding_dim, hidden_dim, n_layers,dropout=0.5)\n","\n","# Move model to GPU\n","if is_CUDA:\n","    print(\"Training on GPU\")\n","    model.cuda()\n","\n","# Create loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","# Train the model\n","#trained_model = train_rnn(model, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)"],"execution_count":196,"outputs":[{"output_type":"stream","text":["Training on GPU\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5YMjCiWEyt--","executionInfo":{"status":"ok","timestamp":1621409185277,"user_tz":420,"elapsed":2208,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}}},"source":["vocab_to_int, int_to_vocab = np.load(\"/content/Encodings.npy\",allow_pickle=True)\n","trained_model = torch.load('/content/trained_LSTM.pt')"],"execution_count":197,"outputs":[]},{"cell_type":"code","metadata":{"id":"V7YA1E4S39mk","executionInfo":{"status":"ok","timestamp":1621409185279,"user_tz":420,"elapsed":2205,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}}},"source":["import torch.nn.functional as F\n","\n","def generate(model, first_word_id, int_to_vocab, predict_len=100):\n","    '''\n","    Generate text using the trained model\n","\n","    Parameters\n","    ----------\n","    model:\n","\n","    first_word_id: int\n","        The integer id of the first word to use to start the text generation\n","    int_to_vocab: dict\n","        Dict of word id keys to word values\n","    predict_len: int\n","        The length of text to generate\n","\n","    Returns\n","    -------\n","        string\n","            The generated text\n","    '''\n","    model.eval()\n","    \n","    current_seq = [first_word_id]\n","    \n","    for _ in range(predict_len):\n","        current_seq_tensor = torch.LongTensor(current_seq[-sequence_length:]).reshape(1,-1)\n","        if is_CUDA:\n","            current_seq_tensor = current_seq_tensor.cuda()\n","        \n","        # Initialize hidden state\n","        hidden = model.init_hidden(1)\n","        \n","        # Forward prop\n","        output, _ = model.forward(current_seq_tensor, hidden)\n","        \n","        # get the next word probabilities\n","        p = F.softmax(output, dim=1).data.cpu()\n","         \n","        # use top_k sampling to get the index of the next word\n","        top_k = 5\n","        p, top_i = p.topk(top_k)\n","        top_i = top_i.numpy().reshape(-1)\n","        \n","        # select the likely next word index with some element of randomness\n","        p = p.numpy().reshape(-1)\n","        word_i = np.random.choice(top_i, p=p/p.sum())\n","        \n","        # Add the generated word to the end of the current sequence\n","        current_seq.append(word_i)\n","    \n","    words_generated = [int_to_vocab[word_id] for word_id in current_seq]\n","    gen_sentences = ' '.join(words_generated)\n","    \n","    # Replace punctuation tokens\n","    for key, token in dict_punctuation.items():\n","        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n","        gen_sentences = gen_sentences.replace(' ' + token, key)\n","    \n","    return gen_sentences"],"execution_count":198,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONOaNH1K6GiD","executionInfo":{"status":"ok","timestamp":1621409185279,"user_tz":420,"elapsed":2201,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"fe89ec8a-28e7-4ab5-953d-602185e8e324"},"source":["gen_length = 100  # Number of words to generate\n","prime_word = 'spongebob'  # First word in the script\n","\n","generated_script = generate(model, vocab_to_int[prime_word], int_to_vocab, gen_length)\n","print(generated_script)"],"execution_count":199,"outputs":[{"output_type":"stream","text":["spongebob sticky package organization package rusty book alive tasty whose tub pfft blueprints krabs' rope moss idiot organization echoing rocket rocket slug rocket timeless wusty rocket slug wusty sticky lullaby stance sticky timeless goldfish *the tub blueprints package package table twins teddy twins organization blueprints lickity miles kitty prophecy prophecy moss urge mock stuck infirmary blueprints decided miles substance devised cherry intelect lawyerpants lawyerpants devilish porchlight organization organization sticky stays whose pilot wallpaper cab table cab open cab frolicked approve emerges jingle wax whose whose moss egad unclogs moss stopped echoing echoing rebuilding mr wakey whose slice stares tasty egad letters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xc68_BU6AO0l","executionInfo":{"status":"ok","timestamp":1621409185280,"user_tz":420,"elapsed":2198,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}},"outputId":"70f693a7-5705-45a0-a25d-ce9f0f499e85"},"source":["from nltk.translate.bleu_score import corpus_bleu\n","test_text = text[int(len(text_encoded)*0.8): int(len(text_encoded)*0.8)+len(generated_script)]\n","score = corpus_bleu(test_text, generated_script)\n","print(score)"],"execution_count":200,"outputs":[{"output_type":"stream","text":["0.6958208456025856\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9ZRV2jTmBCzW","executionInfo":{"status":"ok","timestamp":1621409185550,"user_tz":420,"elapsed":2466,"user":{"displayName":"Moamen Elsayed","photoUrl":"","userId":"04018272351791962551"}}},"source":[""],"execution_count":200,"outputs":[]}]}